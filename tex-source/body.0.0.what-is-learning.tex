\objectives{%
      \item recognize whether a learning task fits the paradigm of
            \emph{learning from examples}
            and whether it's \emph{supervised} or \emph{unsupervised}.
      \item identify within a completed learning-from-examples project:
            the \emph{training inputs(outputs)},
            \emph{testing inputs(outputs)},
            \emph{hypothesis class},
            \emph{learned hypothesis};
            and describe which parts depend on
            which.
}


\sampassage{kinds of learning}
  First, we need to realize that machines and humans do not learn or understand things in the same way. Perhaps, sometimes you have wondered why on some websites we are asked to solve simple image CAPTCHAs!? If we can solve them, then any machine can solve such things very easily (the state-of-the-art machines/computers today, are capable of performing billions of billions (quintillions) of floating-point operations per second!). But, despite what you think, it is one of the most difficult task for a machine to actually "understand" what is in the image.

  Even now, it is safe to assume that nobody completely understands how a human mind works. I still find it very difficult to understand how even I understand things. Sure, it is frustrating to not know how our own mind works, but I think this is the beauty of a human mind.

  So then how shall we approach such a difficult task of teaching machines to do something?

  \textcolor{red}{Needs more work.}

  How do we communicate patterns of desired behavior?  We can teach:
  \begin{description}
    \item[\textbf{by instruction}:  ]  ``to tell whether a mushroom is poisonous, first look at its gills...''
    \item[\textbf{by example}:      ]  ``here are six poisonous fungi; here, six safe ones.  see a pattern?''
    \item[\textbf{by reinforcement}:]  ``eat foraged mushrooms for a month; learn from getting sick.''
  \end{description}
  %
  Machine learning is the art of programming computers to learn from such
  sources.  We'll focus on the most important case: \textbf{learning from
  examples}.\bovinenote{%
    \noparexercise{What's something you've learned by instruction?  By example?
    By reinforcement?}
    %
    In Unit 5 we'll see that learning by example unlocks the
    other modes of learning.
  }

\sampassage{from examples to predictions}
  For us, a pattern of desired behavior is a function that for each given
  situation/prompt returns a favorable action/answer.
  %
  We seek a program that, from a list of examples of prompts and matching
  answers, determines an underlying pattern.  Our program is a success if this
  pattern accurately predicts answers for new, unseen prompts.
  %
  We often define our program as a search, over some class $\hH$ of candidate
  patterns (jargon: \textbf{hypotheses}), to maximize some notion of
  ``intrinsic-plausibility plus goodness-of-fit-to-the-examples''.

  \begin{figure}[h]
    \vspace{-0.5cm}
    \par\noindent\includegraphics[width=\textwidth]{figures/ml-dataflow}
    \caption{%
      \textbf{Predicting mushrooms' poisons.}
      %
      Our learning program selects from a class of hypotheses ({\gre gray blob}) a plausible
      hypothesis that well fits (\textbf{\blu blue dots} are close to
      \textbf{black dots}) a given list of poison-labeled mushrooms ({\blu blue
      blob}).  Evaluating the selected hypothesis on new mushrooms, we predict
      the corresponding poison levels ({\rng orange numbers}).
      %
      \par The arrows show dataflow: how the hypothesis class and the
      mushroom+poisonlevel examples determine one hypothesis, which, together
      with new mushrooms, determines predicted poison levels.
      %
      Selecting a
      hypothesis is called \textbf{learning}; predicting unseen poison levels,
      \textbf{inference}.  The examples we learn from are
      \textbf{training data}; the new mushrooms and their true poison levels
      are \textbf{testing data}.
    }
    \vspace{-1.0cm}
  \end{figure}

  For example, say we want to predict poison levels (answers) of mushrooms
  (prompts).  %Comparing our `\textbf{training data}' to our
  Among our hypotheses,\bovinenote{%
      We choose four hypotheses: respectively, that
      a mushroom's poison level is
      close to:
      \par\emph{--- its ambient soil's percent water by weight};
      \par\emph{--- its gills' odor level, in kilo-Scoville units};
      \par\emph{--- its zipcode (divided by 100000)};
      \par\emph{--- the fraction of visible light its cap reflects}.
  }
  the GillOdor hypothesis fits the examples well: it guesses poison
  levels
  %(\textbf{\blu blue dots})
  close to the truth.
  %(\textbf{black dots}).
  So the program selects GillOdor.
 %(jargon: \textbf{learns})
  %The selection process is called \textbf{learning}.

  `\emph{Wait!}', you say,
  `\emph{doesn't Zipcode fit the example data more closely than GillOdor?'}.
  Yes.  But a poison-zipcode proportionality is implausible: we'd need
  more evidence before believing Zipcode.  We can easily make many oddball
  hypotheses; by chance some may fit our data well, but they probably
  won't predict well!
  %
  Thus
  ``intrinsic plausibility'' and ``goodness-of-fit-to-data''
  \emph{both}\bovinenote{%
    We choose those two notions (and our $\hH$) based on \textbf{domain
    knowledge}.  This design process is an art; we'll study some rules of
    thumb.
  } play a role in learning.

  %We must specify both notions based on our domain knowledge
  %--- this is an art but we'll learn its rules of thumb.
  %
  %We've now met ML's key elements.
  %Those are ML's elements.
  In practice we'll think of each hypothesis as mapping mushrooms to
  \emph{distributions} over poison levels; then its
  ``goodness-of-fit-to-data'' is simply the chance it allots to the
  data.\bovinenote{That's why we'll need \textbf{probability}.}
  %the details are more complex.
  We'll also use huge $\hH$s: we'll \emph{combine} mushroom features
  (wetness, odor, and shine) to make more hypotheses such as
  %Maybe
  $
    (1.0 \cdot \text{GillOdor} - 0.2\cdot \text{CapShine})
  $.\bovinenote{That's why we'll need \textbf{linear algebra}.}
  %predicts poison well!
  %
  Since we can't compute ``goodness-of-fit'' for so many hypotheses,
  we'll guess a hypothesis
  %start at a tentative hypothesis and
  then repeatedly
  nudge it up the ``goodness-of-fit'' \emph{slope}.\bovinenote{That's why we'll need \textbf{derivatives}.}
  %
  %

  %We must specify both notions based on our domain knowledge
  %--- this is an art but we'll learn its rules of thumb.
  %%
  %We'll often do this in terms of \emph{probabilities}:\bovinenote{%
  %  Still, probability isn't the only criterion: if overestimating poison
  %  levels is safer than underestimating them, then we'd want to hedge toward
  %  overestimating.
  %  This will become especially unavoidable when in Unit 5 we learn
  %  from reinforcement.
  %}
  %we supply a distribution over all hypotheses (a \textbf{prior}) and, we think
  %of each hypothesis as mapping mushrooms to \emph{distributions} over poison
  %levels.

  %\bovinenote{%
  %    \textbf{Bayesian Information Criterion}
  %}

\sampassage{supervised learning}
  We'll soon allow uncertainty by letting patterns map prompts to
  \emph{distributions} over answers.
  %\bovinenote{%
  %  Then learning programs have this type:
  %  $$
  %    \lL : (\xX\times \yY)^N \to (\xX\to \text{DistributionsOn}(\yY))
  %  $$
  %}
  %
  Even if there is only one prompt --- say, ``\emph{produce a
  beautiful melody}'' --- we may seek to learn the complicated
  distribution over answers, e.g.\ to generate a diversity of apt
  answers.  Such \textbf{unsupervised learning} concerns output
  structure.
  %
  By contrast, \textbf{supervised learning} (our main subject), concerns
  the input-output relation; it's interesting when there are many possible prompts.
  %there are many possible prompts.
  %
  Both involve learning from examples; the distinction is no more firm
  than that between sandwiches and hotdogs, but the words are good to
  know.

  %To save ink, say that $\xX$ is the set of possible prompts; $\yY$, of
  %possible answers.
  %%
  %With the example above, $\xX$ contains all
  %conceivable mushrooms and $\yY$ contains all conceivable poison
  %levels (perhaps all the non-negative real numbers).
  %%
  %If we like, we can now summarize the data flow in symbols.  A pattern is a
  %function of type $\xX\to\yY$.  And we can model the examples from which our
  %program learns as a list of type $(\xX\times \yY)^N$.  Then a program that
  %learns from examples has type:
  %$$
  %  \lL : (\xX\times \yY)^N \to (\xX\to \yY)
  %$$

%\sampassage{learning as...}
%  TODO
%    %
%\attnsam{
%    machine learning is like science.
%    %
%    machine learning is like automatic programming.
%    %
%    machine learning is like curve-fitting.
%    %%
%    three classic threads of AI
%    }
